% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ABSLOPE.R
\name{ABSLOPE}
\alias{ABSLOPE}
\title{Adaptive Bayesian SLOPE}
\usage{
ABSLOPE(
  Xmis,
  Y,
  start = NULL,
  Xinit = NULL,
  a_prior = 0.01 * NROW(Xmis),
  b_prior = 0.01 * NROW(Xmis),
  Covmat = NULL,
  sigma = NULL,
  FDR = 0.05,
  tol = 1e-04,
  max_iter = 100L,
  verbose = FALSE,
  BH = TRUE
)
}
\arguments{
\item{Xmis}{model matrix}

\item{Y}{numeric. Response variable.}

\item{start}{the initial vector of regression coefficients for the first
iteration. Default to the LASSO estimator obtained after}

\item{Xinit}{model matrix with initially imputed NA values}

\item{a_prior, b_prior}{non-negative parameters of the prior Beta distribution
on theta.}

\item{Covmat}{numeric covariance matrix. Default to identity matrix.}

\item{sigma}{the variance of the noise. Default to 1.}

\item{FDR}{False Discovery Rate. Default to 0.05.}

\item{tol}{optimization tolerance.}

\item{max_iter}{the maximal number of iterations of the optimization
algorithm. Default to 100.}

\item{verbose}{verbosity. Default to FALSE}

\item{BH}{logical. Indicates whether the Benjamini-Hochberg correction for
multiple testing should be used.}
}
\description{
Fit a gaussian model regularized with Adaptive Bayesian SLOPE
and handle missing values by Stochastic Approximation of Expected
Maximization (SAEM)
}
\details{
\code{ABSLOPE} is the combination of SLOPE and Spike-and-Slab
LASSO (SSL). This approach relies on iterations of the weighted SLOPE
algorithm and finds the solution by minimizing
\deqn{
   G(Y,X,\beta) + \sum_{j = 1}^{p} w_j \lambda_{r(\beta,j)}|\beta_j|,
  }{
   G(Y,X,\beta) + \sum w_j |\beta_j|\lambda_r(\beta,j),
  }
where \eqn{r(\beta,j) = {1,2,...,p}} is the rank of \eqn{\beta_j}  among
elements in \eqn{\beta} in a descending order. The weight \eqn{w_j} depends
on the posterior probability that a variable \eqn{X_j} is a true predictor
and is calculated based on the prior knowledge and on the  estimator of
\eqn{\beta_j}, the signal sparsity and its average strength from the
previous iterations.
}
\examples{
set.seed(17)
xy <- SLOPE:::randomProblem(1e2, 200, response = "gaussian")
X <- as.matrix(xy$x)
Y <- xy$y
fit <- ABSLOPE(X, Y)
}
\references{
Jiang, W., Bogdan, M., Josse, J., Majewski, S., Miasojedow, B.,
Ročková, V., & TraumaBase® Group. (2021). Adaptive Bayesian SLOPE: Model
Selection with Incomplete Data. Journal of Computational and Graphical
Statistics, 1-25. \doi{10.1080/10618600.2021.1963263}

Bogdan, M., van den Berg, E., Sabatti, C., Su, W., & Candès, E. J. (2015).
SLOPE -- adaptive variable selection via convex optimization. The Annals of
Applied Statistics, 9(3), 1103–1140. \doi{10/gfgwzt}

Ročková, V., & George, E. I. (2018). The spike-and-slab lasso. Journal of
the American Statistical Association, 113(521), 431-444.
\doi{10.1080/01621459.2016.1260469}
}
